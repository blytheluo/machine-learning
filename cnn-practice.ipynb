{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-19T06:10:05.010056Z","iopub.execute_input":"2021-11-19T06:10:05.010703Z","iopub.status.idle":"2021-11-19T06:10:06.668280Z","shell.execute_reply.started":"2021-11-19T06:10:05.010664Z","shell.execute_reply":"2021-11-19T06:10:06.667448Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\nimport numpy as np # 导入Numpy\nimport pandas as pd # 导入Pandas\nimport os # 导入OS\nimport cv2 # 导入Open CV工具箱\n\n\nprint(os.listdir('../input/flowers-recognition/flowers')) #打印目录结构\ndaisy_dir='../input/flowers-recognition/flowers/daisy' #雏菊目录\nrose_dir='../input/flowers-recognition/flowers/rose' #玫瑰目录\nsunflower_dir='../input/flowers-recognition/flowers/sunflower' #向日葵目录\ntulip_dir='../input/flowers-recognition/flowers/tulip' #郁金香目录\n\n\nX = [] #初始化\ny_label = [] #初始化\nimgsize = 150 #图片大小\n# 定义一个函数读入花的图片\ndef training_data(label,data_dir):\n    print (\"正在读入：\", data_dir) \n    for img in os.listdir(data_dir): #目录\n        path = os.path.join(data_dir,img) #目录+文件名\n        img = cv2.imread(path,cv2.IMREAD_COLOR) #读入图片\n        img = cv2.resize(img,(imgsize,imgsize)) #设定图片像素维度\n        X.append(np.array(img)) #X特征集\n        y_label.append(str(label)) #y标签，即花的类别\n# 读入目录中的图片\ntraining_data('daisy',daisy_dir) #读入雏菊\ntraining_data('rose',rose_dir) #读入玫瑰\ntraining_data('sunflower',sunflower_dir) #读入向日葵\ntraining_data('tulip',tulip_dir) #读入郁金香","metadata":{"execution":{"iopub.status.busy":"2021-11-19T06:10:06.669775Z","iopub.execute_input":"2021-11-19T06:10:06.670007Z","iopub.status.idle":"2021-11-19T06:10:32.470016Z","shell.execute_reply.started":"2021-11-19T06:10:06.669980Z","shell.execute_reply":"2021-11-19T06:10:32.469282Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt # 导入matplotlib\nimport random as rdm # 导入随机数工具\n# 随机显示几张漂亮的花朵图片吧\nfig,ax=plt.subplots(5,2) #画布\nfig.set_size_inches(15,15) #大小\nfor i in range(5):\n    for j in range (2):\n        r=rdm.randint(0,len(X)) #随机选择图片\n        ax[i,j].imshow(X[r]) #显示图片\n        ax[i,j].set_title('Flower: '+y_label[r]) #花的类别\nplt.tight_layout() #绘图","metadata":{"execution":{"iopub.status.busy":"2021-11-19T06:10:32.471029Z","iopub.execute_input":"2021-11-19T06:10:32.471231Z","iopub.status.idle":"2021-11-19T06:10:34.108417Z","shell.execute_reply.started":"2021-11-19T06:10:32.471207Z","shell.execute_reply":"2021-11-19T06:10:34.107533Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\nlabel_encoder =LabelEncoder()\ny = label_encoder.fit_transform(y_label)\ny = to_categorical(y,4)\nX = np.array(X)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T06:10:34.109539Z","iopub.execute_input":"2021-11-19T06:10:34.109748Z","iopub.status.idle":"2021-11-19T06:10:34.829954Z","shell.execute_reply.started":"2021-11-19T06:10:34.109723Z","shell.execute_reply":"2021-11-19T06:10:34.828731Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-19T06:10:34.832407Z","iopub.execute_input":"2021-11-19T06:10:34.832760Z","iopub.status.idle":"2021-11-19T06:10:34.841015Z","shell.execute_reply.started":"2021-11-19T06:10:34.832715Z","shell.execute_reply":"2021-11-19T06:10:34.839884Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"array([[1., 0., 0., 0.],\n       [1., 0., 0., 0.],\n       [1., 0., 0., 0.],\n       ...,\n       [0., 1., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 1., 0., 0.]], dtype=float32)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T06:10:34.842534Z","iopub.execute_input":"2021-11-19T06:10:34.843241Z","iopub.status.idle":"2021-11-19T06:10:35.118013Z","shell.execute_reply.started":"2021-11-19T06:10:34.843193Z","shell.execute_reply":"2021-11-19T06:10:35.116675Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X = X/255","metadata":{"execution":{"iopub.status.busy":"2021-11-19T06:12:11.332151Z","iopub.execute_input":"2021-11-19T06:12:11.332455Z","iopub.status.idle":"2021-11-19T06:12:12.082107Z","shell.execute_reply.started":"2021-11-19T06:12:11.332423Z","shell.execute_reply":"2021-11-19T06:12:12.081402Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T06:12:13.609885Z","iopub.execute_input":"2021-11-19T06:12:13.610304Z","iopub.status.idle":"2021-11-19T06:12:14.348733Z","shell.execute_reply.started":"2021-11-19T06:12:13.610273Z","shell.execute_reply":"2021-11-19T06:12:14.348028Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers # 导入所有层 行1\nfrom tensorflow.keras import models # 导入所有模型 行2\ncnn = models.Sequential() # 贯序模型 行3\ncnn.add(layers.Conv2D(32, (3, 3), activation='relu', # 输入卷积层 行4\n                        input_shape=(150, 150, 3))) \ncnn.add(layers.MaxPooling2D((2, 2))) # 最大池化层 行5\ncnn.add(layers.Conv2D(64, (3, 3), activation='relu')) # 卷积层 行6\ncnn.add(layers.MaxPooling2D((2, 2))) # 最大池化层 行7\ncnn.add(layers.Conv2D(128, (3, 3), activation='relu')) # 卷积层 行8\ncnn.add(layers.MaxPooling2D((2, 2))) # 最大池化层 行9\ncnn.add(layers.Conv2D(128, (3, 3), activation='relu')) # 卷积层 行10\ncnn.add(layers.MaxPooling2D((2, 2))) # 最大池化层 行11\ncnn.add(layers.Flatten()) # 展平层 行12\ncnn.add(layers.Dense(512, activation='relu')) # 全连接层 行13\ncnn.add(layers.Dense(4, activation='softmax')) # 分类输出层 行14\ncnn.compile(loss='categorical_crossentropy', # 损失函数 行15\n            optimizer='RMSprop', # 优化器\n            metrics=['acc']) # 评估指标","metadata":{"execution":{"iopub.status.busy":"2021-11-19T06:12:15.884383Z","iopub.execute_input":"2021-11-19T06:12:15.884807Z","iopub.status.idle":"2021-11-19T06:12:15.982805Z","shell.execute_reply.started":"2021-11-19T06:12:15.884776Z","shell.execute_reply":"2021-11-19T06:12:15.981962Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from IPython.display import SVG # 实现神经网络结构的图形化显示\nfrom tensorflow.keras.utils import model_to_dot # 导入model_to_dot工具\nSVG(model_to_dot(cnn).create(prog='dot', format='svg')) # 绘图","metadata":{"execution":{"iopub.status.busy":"2021-11-19T06:12:51.203006Z","iopub.execute_input":"2021-11-19T06:12:51.203282Z","iopub.status.idle":"2021-11-19T06:12:52.124003Z","shell.execute_reply.started":"2021-11-19T06:12:51.203246Z","shell.execute_reply":"2021-11-19T06:12:52.123307Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# 训练网络并把训练过程信息存入history对象\nhistory = cnn.fit(X_train,y_train, #训练数据\n                  epochs=10, #训练轮次（梯度下降）\n                  validation_split=0.2) #训练的同时进行验证","metadata":{"execution":{"iopub.status.busy":"2021-11-19T06:24:54.426896Z","iopub.execute_input":"2021-11-19T06:24:54.428000Z","iopub.status.idle":"2021-11-19T06:30:14.254974Z","shell.execute_reply.started":"2021-11-19T06:24:54.427951Z","shell.execute_reply":"2021-11-19T06:30:14.254359Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def show_history(history): # 显示训练过程中的学习曲线\n    loss = history.history['loss'] #训练损失\n    val_loss = history.history['val_loss'] #验证损失\n    epochs = range(1, len(loss) + 1) #训练轮次\n    plt.figure(figsize=(12,4)) # 图片大小\n    plt.subplot(1, 2, 1) #子图1\n    plt.plot(epochs, loss, 'bo', label='Training loss') #训练损失\n    plt.plot(epochs, val_loss, 'b', label='Validation loss') #验证损失\n    plt.title('Training and validation loss') #图题\n    plt.xlabel('Epochs') #X轴文字\n    plt.ylabel('Loss') #Y轴文字\n    plt.legend() #图例\n    acc = history.history['acc'] #训练准确率\n    val_acc = history.history['val_acc'] #验证准确率\n    plt.subplot(1, 2, 2) #子图2\n    plt.plot(epochs, acc, 'bo', label='Training acc') #训练准确率\n    plt.plot(epochs, val_acc, 'b', label='Validation acc') #验证准确率\n    plt.title('Training and validation accuracy') #图题\n    plt.xlabel('Epochs') #X轴文字\n    plt.ylabel('Accuracy') #Y轴文字\n    plt.legend() #图例\n    plt.show() #绘图\nshow_history(history) # 调用这个函数","metadata":{"execution":{"iopub.status.busy":"2021-11-19T06:32:10.906943Z","iopub.execute_input":"2021-11-19T06:32:10.907745Z","iopub.status.idle":"2021-11-19T06:32:11.290403Z","shell.execute_reply.started":"2021-11-19T06:32:10.907691Z","shell.execute_reply":"2021-11-19T06:32:11.289521Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"result = cnn.evaluate(X_test, y_test) #评估测试集上的准确率\nprint('CNN的测试准确率为',\"{0:.2f}%\".format(result[1]))","metadata":{"execution":{"iopub.status.busy":"2021-11-19T06:32:13.754222Z","iopub.execute_input":"2021-11-19T06:32:13.754507Z","iopub.status.idle":"2021-11-19T06:32:16.310781Z","shell.execute_reply.started":"2021-11-19T06:32:13.754460Z","shell.execute_reply":"2021-11-19T06:32:16.309907Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"prediction = cnn.predict(X_test) #预测测试集的图片分类","metadata":{"execution":{"iopub.status.busy":"2021-11-19T06:32:19.864409Z","iopub.execute_input":"2021-11-19T06:32:19.864693Z","iopub.status.idle":"2021-11-19T06:32:22.489226Z","shell.execute_reply.started":"2021-11-19T06:32:19.864662Z","shell.execute_reply":"2021-11-19T06:32:22.488538Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"prediction[0] #第一张图片的分类","metadata":{"execution":{"iopub.status.busy":"2021-11-19T06:32:30.452217Z","iopub.execute_input":"2021-11-19T06:32:30.452894Z","iopub.status.idle":"2021-11-19T06:32:30.459462Z","shell.execute_reply.started":"2021-11-19T06:32:30.452848Z","shell.execute_reply":"2021-11-19T06:32:30.458545Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print('第一张测试图片的分类结果为:', np.argmax(prediction[0]))","metadata":{"execution":{"iopub.status.busy":"2021-11-19T06:32:37.777323Z","iopub.execute_input":"2021-11-19T06:32:37.778138Z","iopub.status.idle":"2021-11-19T06:32:37.784105Z","shell.execute_reply.started":"2021-11-19T06:32:37.778091Z","shell.execute_reply":"2021-11-19T06:32:37.783350Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}